## 1.Redis支持的数据类型

### 1.1.String字符串

格式：set key value

string类型是二进制安全的，意思是redis的string可以包含任何数据。比如jpg图片或者序列化的对象。

string类型是redis最基本的数据类型，一个键最大能存储512MB。

### 1.2.Hash(哈希)

格式：hmset name key1 value1 key2 value2

redis hash是一个键值对的集合。

Redis hash是一个string类型的field和value的映射表，hash特别适合用于存储对象。

### 1.3.List(列表)

redis列表是简单的字符串列表，按照插入顺序排序。你可以添加一个元素到列表的头部(左边)或者右边。

格式：lpush name value 在key对应的list的头部添加字符串元素。

格式：rpush name value在key对应的list的尾部添加字符串元素。

格式：lrem name index  key对应list中删除count个和value相同的元素。

格式：llen name 返回key对应list的长度。

### 1.4.Set(集合)

格式：sadd name value

redis的set是string类型的无序集合。

集合是通过哈希表实现的，所以添加、删除、查找的复杂度都是O(1)。

### 1.5.SortedSet(有序集合)

格式：zadd name score value

redis zset和set一样也是string类型元素的集合，且不允许重复的成员。

不同的是每个元素都会关联一个double类型的分数。redis正是通过分数来为集合中的成员进行从小到大的排序。

zset的成员是唯一的，但是却可以重复。

## 2.Redis的单线程模型

### 2.1.IO多路复用程序

Redis基于reactor模式开发了网络事件处理器，这个处理器叫做文件事件处理器，file event handler。这个文件事件处理器，是单线程的，所以Redis才叫做单线程的模型，采用IO多路复用机制同时监听多个socket，根据socket上的事件来选择对应的时间处理器来处理这个事件。

如果被监听的socket准备好执行accept、read、write、close等操作的时候，跟操作对应的文件事件就会产生，这个时候文件事件处理器就会调用之前关联好的事件处理器来处理这个事件。

文件事件处理器是单线程模式运行的，但是通过IO多路复用机制监听多个socket，可以实现高性能的网络通讯模型，又可以跟内部其他其它单线程的模块进行对接，保证了Redis内部的线程模型的简单性。

文件时间处理器的结构包含4个部分：多个socket、IO多路复用程序、文件时间分派器、事件处理器(命令请求处理器、命令回复处理器、连接应答处理器等等)。

多个socket可能并发的产生不同的操作，每个操作对应不同的文件事件，IO多路复用程序会监听多个socket，但是**会将socket放入到一个队列中排队**，每次从队列中取出一个socket给事件分配器，事件分配器把socket给对应的事件处理器。

然后一个socket的事件处理完之后，IO多路复用程序才会将队列中的下一个socket给事件分派器。文件事件分派器会根据每个socket当前产生的事件，来选择对应的事件处理器来处理。

### 2.2.文件事件

当socket变得可读时(比如客户端对redis执行write操作，或者close操作)，或者有新的可以应答的socket出现时(客户端对redis执行connect操作)，socket就会产生一个AE_READABLE事件。

当socket变得可写的时候(客户端对redis执行read操作)，socket会产生一个AE_WRITEABLE事件。

IO多路复用程序可以同时监听AE_READABLE和AE_WRITEABLE两种事件，要是一个sokcet同时产生了AE_READABLE和AE_WRITEABLE两种事件，那么文件事件分派器优先处理AE_READABLE事件，然后才是AE_READABLE事件。

### 2.3.文件事件处理器

如果是客户端要连接redis，那么会为socket关联连接应答处理器。

如果是客户端要写数据到redis，那么会为socket关联命令请求处理器。

如果是客户端要从redis读数据，那么会为socket关联命令回复处理器。

### 2.4.客户端与Redis通信的一次流程

在Redis启动初始化的时候，Redis会将连接应答处理器跟AC_READABLE事件关联起来，接着如果一个客户端跟Redis发起连接，此时会产生一个AC_READABLE事件，然后由连接应答处理器跟客户端建立连接，创建客户端对应的socket，同时将这个socket的AC_READABLE事件和命令请求处理器关联起来。

当客户端向Redis发起请求的时候(读写请求都是一样)，首先就会在socket产生一个AC_READABLE事件，然后由对应的命令请求处理器来处理。这个命令请求处理器就会从socket中读取请求相关数据，然后进行执行和处理。

接着Redis这边准备好了给客户端的响应数据之后，就会将socket的AE_WRITABLE事件跟命令回复处理器关联起来，当客户端这边准备好读取响应数据的时候，就会在socket上产生一个AE_WRITABLE事件，会由对应的命令回复处理器来处理，就是将准备好的响应数据写入socket，供客户端读取。

命令回复处理器写完之后，就会删除这个socket的AE_WRITABLE事件和命令回复处理器的关联关系。

## 3.设置过期时间的key怎么删除

如果假设你设置一个一批key只能存活1个小时，那么接下来1小时后，redis是怎么对这批key进行删除的？

答案是：定期删除+惰性删除

### 3.1.定期删除

所谓定期删除，指的是Redis默认是每隔100ms就随机抽取一些设置了过期时间的key，检查其是否过期，如果过期就删除。假设redis里放了10万个key，都设置了过期时间，你每隔几百毫秒，就检查10万个key，那基本上redis就死了，CPU负载会很高的，消耗在你的检查过期key上了。注意，这里可不是每隔100ms就遍历所有的设置过期时间的key，那样就是一场性能上的灾难。实际上redis是每隔100ms随机抽取一些key来检查和删除的。

### 3.2.惰性删除

但问题是，定期删除可能会导致很多过期key到了时间并没有被删除掉，那咋整呢？所以就需要惰性删除了。

惰性删除就是说，在你获取某个key的时候，redis会检查一下，这个设置了过期时间的key是否过期了呢？如果过期了此时就会删除，不会给你返回任何东西。

## 4.Redis的内存(LRU)淘汰策略

### Redis的常规处理流程概述

如果Redis系统支持LRU功能，其处理流程如下：

1.客户端向Redis系统发送命令，Redis系统解析命令，为命令参数分配内存空间。

2.Redis检查内存使用情况是否超过限定值maxmemory，如果超过限定值，根据淘汰算法进行释放。

3.如果客户端是读取命令，则忽略淘汰算法的结果，继续执行客户端的命令。如果是写命令(导致内存使用增加)，根据淘汰算法的结果进行处理，如果淘汰算法无法释放足够的空间，则向客户端写命令返回错误响应，如果淘汰算法释放了足够的内存，则继续执行该写命令。

### Redis中LRU的实现

1.Redis维护了一个全局的24位的时钟(每隔一定时间会更新这个时间戳。每个key对象内部同样维护了一个24位的时钟(**lruclock**)，当新增对象的时候会把系统的时钟赋值给这个对象的时钟，比如我现在要进行LRU，那么首先拿到当前的全局时钟，然后再找到内部时钟和全局时钟距离最久的(差最大)进行淘汰，这里值得注意的是全局时钟只有24位，按秒为单位来表示才能存储194天，所以可能会出现key的时钟大于全局时钟的情况，如果这种情况出现那么就两个相加而不是相减来求最久的key。

Redis中的LRU与常规的LRU实现并不相同，常规LRU会准确的淘汰掉对头的元素，但是Redis的LRU并不维护队列，只是根据配置的策略要么从所有的key中随机选择N个(默认是5个)，要么从所有的设置了过期时间的key中选出N个键(默认是5个)，然后再从这个N个键中选出最久没有使用的一个key进行淘汰。

### **要不你手写一个LRU算法？**

```java
public class LRUCache<K, V> extends LinkedHashMap<K, V> {
    
private final int CACHE_SIZE;
 
    // 这里就是传递进来最多能缓存多少数据
    public LRUCache(int cacheSize) {
        // 这块就是设置一个hashmap的初始大小，同时最后一个true指的是让linkedhashmap
        // 按照访问顺序来进行排序，最近访问的放在头，最老访问的就在尾
        super((int) Math.ceil(cacheSize / 0.75) + 1, 0.75f, true);
        CACHE_SIZE = cacheSize;
    }
 
    @Override
    protected boolean removeEldestEntry(Map.Entry eldest) {
        // 这个意思就是说当map中的数据量大于指定的缓存个数的时候，就自动删除最老的数据
        return size() > CACHE_SIZE; 
    }
}
```

## 5.怎么保证Redis是高并发以及高可用的

**Redis高并发：**主从架构，一主多从，一般来说，很多项目其实就足够了，单主用来写入数据，单机几万QPS，多从用来查询数据，多个从实例可以提供每秒10万的QPS。

**Redis高可用：**如果你做主从架构部署，其实就是加上哨兵就可以了，就可以实现，任何一个实例宕机，自动会进行主备切换。

### 5.1.主从复制

Redis的复制(replication)功能允许用户根据一个Redis服务器来创建任意多个该服务器的复制品，其中被复制的服务器为主服务器(master)，而同过复制创建出来的服务器复制品则为从服务器(slave)。只要出从服务器直接的网络连接正常，主从服务器两者会具有相同的数据，主服务器就会一直将发生在自己身上的数据更新同步给从服务器，从而一直保证主从服务器的数据相同。

### 5.2.哨兵模式

Redis sentinel是一个分布式系统中监控redis主从服务器，并在主服务器下线时自动进行故障转移。其中三个特性：

监控(monitoring)：sentinel会不断检查你的主服务器和从服务器是否运作正常。

提醒(notification)：当被监控的某个Redis服务器出现问题时，sentinel可以通过API向管理员或者其他应用程序发送通知。

自动故障转移(automatic failover)：当一个主服务器不能正常工作时，sentinel会开始一次自动故障迁移工作。

## 6.怎么保证Redis挂掉之后的数据恢复

### 6.1.RDB

rdb就是Redis DataBase的缩写。

功能核心函数rdbSave(生成rdb文件)和rdbLoad(从文件加载内存)两个函数。

![https://img2018.cnblogs.com/blog/1481291/201809/1481291-20180925141429889-1694430603.png](file:///C:\Users\LIUSHU~1\AppData\Local\Temp\msohtmlclip1\01\clip_image002.png)

### 6.2.AOF

AOF是Append-only file缩写。

每当执行服务器(定时)任务或者函数时flushAppendOnlyFile函数都会被调用，这个函数执行以下两个工作：

WRITE：根据条件，将aof_buf中的缓存写入到AOF文件。

SAVE：根据条件，调用fsync或fdatasync函数，将AOF文件保存到磁盘中。

## 7.聊聊Redis Cluster集群模式的原理(待写)

### 7.1.集群模式的工作原理

Redis Cluster介绍：

1.**自动将数据进行分片，每个master上放一部分数据，一条数据只存放在一台master上**。

2.**提供内置的高可用支持，部分master不可用时，自动进行主从切换，还是可以继续工作的**。

在Redis Cluster架构下，每个Redis要放开两个端口号，比如一个是6379，另外一个就是加1w的端口号(16379)。

19379端口号是用来进行节点间通信的，也就是Cluster Bus的东西，Cluster Bus的通信，用来进行故障检测、配置更新、故障转移授权。Cluster Bus用了另外一种二进制的协议，gossip协议，用于节点间进行高效的数据交换，占用更少的网络带宽和处理时间。

Redis Cluster节点间采用gossip协议进行通信。以此来维护集群元数据，所有的节点都持有一份元数据，不同的节点如果出现了元数据的变更，就不断的将元数据发送到其它的节点，让其它节点也进行元数据的变更。

gossip好处在于，元数据的更新比较分散，不是集中在一个地方，更新请求会陆陆续续，达到所有节点进行更新，降低了压力；不好在于，元数据的更新有延迟，可能会导致集群中的一些操作会有一些滞后。

**gossip协议包含多种信息：**

1.meet：某个节点发送meet给新加入的节点，让新节点加入集群中，然后新节点就会开始与其他节点j进行通信。其实内部就是发送了一个gossip meet消息给新加入的节点，通知那个节点去加入我们的集群。

2.ping：每个节点都会频繁给其他节点发送ping，其中包含自己的状态还有自己维护的集群元数据，互相通过ping交换元数据。

3.pong：返回ping和meet，包含自己的状态和其它信息，也用于信息广播和更新。

4.fail：某个节点判断另外一个节点fail之后，就发送fail给其它节点，通知其它节点说，某个节点宕机了。

**ping消息深入**

ping时要携带一些元数据，如果很频繁，可能会加重网络负担。

每个节点每秒会执行10次ping，每次会选择5个最久没有通信的其他节点。当然如果发现某个节点通信延迟达到了cluster_node_timeout/2，那么立即发送ping，避免数据交换延迟过长，落后的时间太长了。比如说，两个节点10分钟没有交换数据了，那么整个集群处于严重不一致的情况，就会有问题。所以cluster_node_timeout可以调节，如果调的比较大，那么会降低ping的频率。

每次ping，会带上自己节点的信息，还有就是带上1/10其他节点的信息，发送出去，进行交换。最少包含2个其它节点的信息，最多包含N-2个节点的信息。

### 7.2.在集群模式下，Redis 的 key 是如何寻址的

### 7.3.hash算法

来一个key，首先计算hash值，然后对节点数取模。然后打到不同的master节点上。一旦节点宕机或新增节点，在这一时刻，大量的缓存命不中，缓存数据需要重新建立，甚至是进行整体的缓存数据迁移，这会导致**大部分的请求过来，全部无法拿到有效的缓存**，导致大量的流量涌入数据库。

### 7.4.一致性 hash 算法

 简单来说，一致性哈希将整个哈希值空间组织成一个虚拟的圆环，如假设某哈希函数H的值空间为(即哈希值是一个32位无符号整形)，

下一步将各个服务器使用H进行一个哈希，具体可以选择服务器的ip或主机名作为关键字进行哈希，这样每台机器就能确定其在哈希环上的位置，

接下来使用算法定位数据访问到相应服务器：将数据key使用相同的函数H计算出哈希值h，通根据h确定此数据在环上的位置，从此位置沿环顺时针“行走”，第一台遇到的服务器就是其应该定位到的服务器。

在一致性hash算法中，如果一个节点挂了，受影响的数据仅仅是此节点到环空间前一个节点之间的数据，其它不受影响。增加一个节点也同理。

一致性哈希算法在服务节点太少时，容易因为节点分部不均匀而造成数据倾斜问题。为了解决这种数据倾斜问题，一致性哈希算法引入了虚拟节点机制，即对每一个服务节点计算多个哈希，每个计算结果位置都放置一个此服务节点，称为**虚拟节点**。

### 7.5.Redis Cluster 的高可用与主备切换原理

Redis Cluster 的高可用的原理，几乎跟哨兵是类似的。

1.**判断节点宕机**

如果一个节点认为另外一个节点宕机，那么就是pfail，**主观宕机**。如果多个节点都认为另外一个节点宕机了，那么就是fail，**客观宕机**，跟哨兵的原理几乎一样，sdown，odown。

在cluster-node-timeout内，某个节点一直没有返回pong，那么就认为pfail。

如果一个节点认为某个节点pfail了，那么会在gossip ping消息中，ping给其它节点，如果**超过半数**的节点都认为pfail了，那么就会变成fail。

2.**从节点过滤**

对宕机的master node，从其所有的slave node中，选择一个切换成master node。

检查每个slave node与master node断开连接的时间，如果超过了超过时间限制，那么就**没有资格**成为master。

3.**从节点选举**

每个从节点，都根据自己对master复制数据的offset，来设置一个选举时间，offset越大(复制数据越多)的从节点，选举时间越靠前，优先进行选举。

所有的master node开始slave选举投票，给要进行选举的salve进行投票，如果大部分的投票都给了某个从节点，那么选举通过，那个从节点可以切换成master。

从节点执行主备切换，从节点切换为主节点。

整个流程跟哨兵相比，非常类似，所以说，Redis Cluster功能强大，直接集成了replication 和 sentinel 的功能。

## 8.如何应对缓存雪崩以及穿透问题

### 8.1.缓存穿透

**缓存穿透：**一般的缓存系统，都是按照key去缓存查询，如果不存在对应的value，就应该去后端系统查找(比如DB)。一些恶意的请求会故意查询不存在的key，请求量很大，就会对后端系统造成很大的压力。这就叫做缓存穿透。

**如何避免缓存穿透：**

1.对于查询结果为空的情况也进行缓存，缓存时间设置的短一点，或者该key对应的数据insert了之后清理缓存。

### 8.2.缓存雪崩

**缓存雪崩**：当缓存服务器重启或者大量缓存集中在某一时刻失效，这样在失效的时候，会给后端系统带来很大的压力。导致系统崩溃。

**如何避免缓存雪崩：**

事前：redis高可用，主从+哨兵，redis cluster，避免全盘崩溃。

事中：本地JVM缓存 + hystrix限流&降级，避免MySQL被打死。

事后：redis持久化，快速恢复缓存数据。

## 9.Redis的并发竞争问题该如何解决

**Redis 事务的CAS方案**

这个也是线上非常常见的一个问题，就是**多客户端同时并发写**一个 key，可能本来应该先到的数据后到了，导致数据版本错了；或者是多客户端同时获取一个 key，修改值之后再写回去，只要顺序错了，数据就错了。

而且 Redis 自己就有天然解决这个问题的 CAS 类的乐观锁方案。

## 10.Redis分布式锁

**实现思想**

1.获取锁的时候，使用setnx加锁，并使用expire命令为锁添加一个超时时间，超过该时间则自动释放锁，锁的value值为一个随机生成的UUID，通过此在释放锁的时候进行判断。

2.获取锁的时候还设置一个获取的超时时间，若超过这个时间则放弃获取锁。

3.释放锁的时候，通过LUA脚本释放，即删除这个key。

**使用命令介绍**

SETNX：SETNX key val：当且仅当key不存在时，set一个key为val的字符串，返回1；若key存在，则什么都不做，返回0。

expire：expire key timeout：为key设置一个超时时间，单位为second，超过这个时间锁会自动释放，避免死锁。

**注意事项**

1.**潜在死锁**

如果在加锁和解锁中间执行的业务中断，比如服务器挂了，或者线程被杀掉，那么就可能会**导致del指令没有被调用**，这样就会**陷入死锁**，锁永远得不到释放。

那么实际应用中我们应该给锁加上过期时间，比如5秒，由于 **setnx 和 expire 非原子性**，如果在 setnx 和 expire 之间出现机器挂掉或者是被人为杀掉，就会导致死锁。

加锁正确姿势：

```java
String result = jedis.set("lock-key", String.valueOf(System.currentTimeMillis(), "NX", "PX", 5);
if ("OK".equals(result)) {
    return true;
}
return false;
```

2.**超时时间**

考虑如下场景，加锁和解锁之间的业务非常耗时，那么就可能存在：

​	线程一拿到锁之后执行业务
​	还没执行完锁就超时过期了
​	线程二此时拿到锁乘虚而入，开始执行业务...

当然这是 redis 分布式锁在死锁和超时问题之间做出的妥协，没办法完全避免，但是需要业务在使用时，衡量加锁的粒度及过期时间。

**3.集群环境如何保证锁的安全**

Redis分布式锁在集群环境下，不是绝对的安全的。比如：主节点的锁还没来得及同步到从节点，此时主节点挂了，从节点取而代之。

线程1在主节点已经成功拿到一把锁，此时切到了从节点，这把锁不存在了，此时线程2轻松在从节点取到这把锁，这就导致一把锁被两个线程拿到了。

Redlock 算法就是为了解决这个问题，他的原理是在加锁时，向过半节点发送 set 指令，只要过半节点返回成功，那就认为加锁成功。释放锁时，再向所有节点发送 del 指令。